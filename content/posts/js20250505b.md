+++
title = "ubuntu 22.04 部署RAGFlow开源 RAG知识库"
date = 2025-05-05
subtitle = ""
description = "ubuntu 22.04 部署RAGFlow开源RAG知识库"
author = ""
image = ""
tags =  ["服务器","AI"]
categories = ["技术笔记" ]
featured = false # 是否把本文设置为精选
draft = false
+++

RAGFlow 是一个基于深度文档理解的开源 RAG（Retrieval-Augmented Generation，检索增强生成）引擎，能够为个人和各种规模的企业提供高效的 RAG 工作流程，结合大语言模型（LLM）与深度文档理解技术，针对复杂格式的数据（如 Word、PDF、Excel、PPT、图像、网页等）提供准确的问答功能，并生成带有可靠引用的回答，其核心优势在于能够从非结构化数据中提取知识，处理大规模文档，并在检索过程中实现高精度和可解释性。

部署 RAGFlow 建议的最小配置：  
CPU >= 4 核  
RAM >= 16 GB  
Disk >= 50 GB  
Docker >= 24.0.0 & Docker Compose >= v2.26.1  
当然，最好要有GPU了。

>下面在是ubuntu 22.04中使用Docker来安装 RAGFlow

在安装 RAGFlow 前需要将系统的内核参数 vm.max_map_count 设置为不小于 262144。vm.max_map_count 是 Linux 内核的一个虚拟内存管理参数。  
`sudo sysctl -w vm.max_map_count=262144`  
永久生效需编辑 /etc/sysctl.conf，添加 `vm.max_map_count=262144`  

克隆仓库：  
`git clone https://github.com/infiniflow/ragflow.git`  
`cd ragflow/docker`  

使用默认的配置文件启动 Docker 容器（无GPU）：  
`sudo docker compose -f docker-compose.yml up -d`   
![662a571c05d9f4bdce470b966b776af9.png](/img/662a571c05d9f4bdce470b966b776af9.png)     

如果有GPU，则执行这条命令来启动 Docker 容器：  
`sudo docker compose -f docker-compose-gpu.yml up -d`  
 ![0a8fde5e330c71fe63548ae4901bca1a.png](/img/0a8fde5e330c71fe63548ae4901bca1a.png)  

注：以上命令会自动下载 RAGFlow slim Docker 镜像 v0.17.0-slim。如需下载不同于 v0.17.0-slim 的 Docker 镜像，请在运行 docker compose 启动服务之前先更新 docker/.env 文件内的 RAGFLOW_IMAGE 变量。比如，你可以通过设置 RAGFLOW_IMAGE=infiniflow/ragflow:v0.17.0 来下载 RAGFlow 镜像的 v0.17.0 完整发行版。

![9ed5f3eb56d8618a5f4ff0480188e7e0.png](/img/9ed5f3eb56d8618a5f4ff0480188e7e0.png)    

如果遇到 Docker 镜像拉不下来的问题，可以在 docker/.env 文件内根据变量 RAGFLOW_IMAGE 的注释提示选择华为云或者阿里云的相应镜像。  
华为云镜像名：swr.cn-north-4.myhuaweicloud.com/infiniflow/ragflow  
阿里云镜像名：registry.cn-hangzhou.aliyuncs.com/infiniflow/ragflow

成功启动容器后，使用如下命令查看容器日志：  
sudo docker logs -f ragflow-server  
![9dcf9ba83dfa5d8df67b3c16c54ccac7.png](/img/9dcf9ba83dfa5d8df67b3c16c54ccac7.png)

在浏览器中输入的服务器对应的 IP 地址并登录 RAGFlow，就可以开始使用了。

添加模型  
(注：需先安装ollama，这里略过)  
先使用ollama下载并运行模型  
ollama run llama3.2 聊天模型  
ollama run bge-m3 嵌入模型  
![3c29f2c49aa52d4d6700f79a44c64986.png](/img/3c29f2c49aa52d4d6700f79a44c64986.png)

添加聊天对话模型

![ac968220950a0846ccc0cb9081907022.png](/img/ac968220950a0846ccc0cb9081907022.png)

![97b16faba3768d9256afa74ecea2f5d7.png](/img/97b16faba3768d9256afa74ecea2f5d7.png)

![f0ea3dc79e6539b433c26d2637f3a7d4.png](/img/f0ea3dc79e6539b433c26d2637f3a7d4.png)

加入嵌入模型  
![99275bcd6d4efac305ee0d72a063ab46.png](/img/99275bcd6d4efac305ee0d72a063ab46.png)

新建知识库并进行配置  
![9d9b4a43129ba9152f33758e7a5feeb8.png](/img/9d9b4a43129ba9152f33758e7a5feeb8.png)

加入的文档，要先进行解析，否则会出现 “102 No chunk found! Check the chunk status please!”错误提示  
![ce8c244ac01705eef80657e38a2e33db.png](/img/ce8c244ac01705eef80657e38a2e33db.png)

![b3d04486b9eaa119b99cad43e9ef2063.png](/img/b3d04486b9eaa119b99cad43e9ef2063.png)

如果修改了配置文件  
所有系统配置都需要通过系统重启生效：  
sudo docker compose -f docker-compose.yml up -d  

停止所有容器运行:  
docker compose -f docker/docker-compose.yml down -v  
其中 -v 将会删除 docker 容器的 volumes，已有的数据会被清空

如果 RAGFlow 在 Docker 中运行，并且 Ollama 在同一台主机上运行，请检查是否可以从 RAGFlow 容器内部访问 ollama：  
先进入 ragflow 容器：  
`sudo docker exec -it ragflow-server bash`    
再执行  
`curl http://host.docker.internal:11434/`    
如果正常应该返回信息：  
Ollama is running  
